## Проект по Spark.  

Исходные данные лежат в [clickstream.parquet](https://github.com/andreikrutov/Big_Data_Stepik/blob/main/PySpark/spark_project/clickstream.parquet).  
Схема данных:  
*date* - день, в который происходят события  
*time* - точное время события  
*event*	- тип события, может быть или показ или клик по рекламе  
*platform* -	платформа, на которой произошло рекламное событие  
*ad_id*	- id рекламного объявления  
*client_union_id*	- id рекламного клиента  
*campaign_union_id*	- id рекламной кампании  
*ad_cost_type* -	тип объявления с оплатой за клики (CPC) или за показы (CPM)  
*ad_cost*	- стоимость объявления в рублях, для CPC объявлений - это цена за клик, для CPM - цена за 1000 показов  
*has_video*	- есть ли у рекламного объявления видео  
*target_audience_count*	- размер аудитории, на которую таргетируется объявление  

Эти данные необходимо привести к виду:  
*ad_id*	- id рекламного объявления  
*target_audience_count*	-	размер аудитории, на которую таргетируется объявление  
*has_video*	- 1 если есть видео, иначе 0  
*is_cpm*	- 1 если тип объявления CPM, иначе 0  
*is_cpc*	- 1 если тип объявления CPC, иначе 0   
*ad_cost*	- стоимость объявления в рублях  
*day_count*	- Число дней, которое показывалась реклама  
*CTR*	-	Отношение числа кликов к числу просмотров  

Далее необходимо реализовать скрипт, который при выполнении команды,  
например, 

**python PySparkJob.py clickstream.parquet result**

должен прочитать указанный в параметрах файл, обработать его и получить структуру папок вида:  
**/result/train**    
**/result/test**  
С наборами данных в следующем соотношении train/test = 0.75/0.25 (randomSplit).
